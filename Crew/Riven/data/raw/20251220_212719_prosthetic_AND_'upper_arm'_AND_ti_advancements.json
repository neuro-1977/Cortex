[
  {
    "title": "Introducing V-Soft Pro: a Modular Platform for a Transhumeral Prosthesis with Controllable Stiffness",
    "summary": "Current upper limb prostheses aim to enhance user independence in daily activities by incorporating basic motor functions. However, they fall short of replicating the natural movement and interaction capabilities of the human arm. In contrast, human limbs leverage intrinsic compliance and actively modulate joint stiffness, enabling adaptive responses to varying tasks, impact absorption, and efficient energy transfer during dynamic actions. Inspired by this adaptability, we developed a transhumeral prosthesis with Variable Stiffness Actuators (VSAs) to replicate the controllable compliance found in biological joints. The proposed prosthesis features a modular design, allowing customization for different residual limb shapes and accommodating a range of independent control signals derived from users' biological cues. Integrated elastic elements passively support more natural movements, facilitate safe interactions with the environment, and adapt to diverse task requirements. This paper presents a comprehensive overview of the platform and its functionalities, highlighting its potential applications in the field of prosthetics.",
    "published": "2025-12-04T17:11:22Z",
    "link": "http://arxiv.org/abs/2512.04998v1"
  },
  {
    "title": "Reconstruction of Surface EMG Signal using IMU data for Upper Limb Actions",
    "summary": "Surface Electromyography (sEMG) provides vital insights into muscle function, but it can be noisy and challenging to acquire. Inertial Measurement Units (IMUs) provide a robust and wearable alternative to motion capture systems. This paper investigates the synthesis of normalized sEMG signals from 6-axis IMU data using a deep learning approach. We collected simultaneous sEMG and IMU data sampled at 1~KHz for various arm movements. A Sliding-Window-Wave-Net model, based on dilated causal convolutions, was trained to map the IMU data to the sEMG signal. The results show that the model successfully predicts the timing and general shape of muscle activations. Although peak amplitudes were often underestimated, the high temporal fidelity demonstrates the feasibility of using this method for muscle intent detection in applications such as prosthetics and rehabilitation biofeedback.",
    "published": "2025-11-21T12:26:33Z",
    "link": "http://arxiv.org/abs/2511.17200v1"
  },
  {
    "title": "BRAVE: Brain-Controlled Prosthetic Arm with Voice Integration and Embodied Learning for Enhanced Mobility",
    "summary": "Non-invasive brain-computer interfaces (BCIs) have the potential to enable intuitive control of prosthetic limbs for individuals with upper limb amputations. However, existing EEG-based control systems face challenges related to signal noise, classification accuracy, and real-time adaptability. In this work, we present BRAVE, a hybrid EEG and voice-controlled prosthetic system that integrates ensemble learning-based EEG classification with a human-in-the-loop (HITL) correction framework for enhanced responsiveness. Unlike traditional electromyography (EMG)-based prosthetic control, BRAVE aims to interpret EEG-driven motor intent, enabling movement control without reliance on residual muscle activity. To improve classification robustness, BRAVE combines LSTM, CNN, and Random Forest models in an ensemble framework, achieving a classification accuracy of 96% across test subjects. EEG signals are preprocessed using a bandpass filter (0.5-45 Hz), Independent Component Analysis (ICA) for artifact removal, and Common Spatial Pattern (CSP) feature extraction to minimize contamination from electromyographic (EMG) and electrooculographic (EOG) signals. Additionally, BRAVE incorporates automatic speech recognition (ASR) to facilitate intuitive mode switching between different degrees of freedom (DOF) in the prosthetic arm. The system operates in real time, with a response latency of 150 ms, leveraging Lab Streaming Layer (LSL) networking for synchronized data acquisition. The system is evaluated on an in-house fabricated prosthetic arm and on multiple participants highlighting the generalizability across users. The system is optimized for low-power embedded deployment, ensuring practical real-world application beyond high-performance computing environments. Our results indicate that BRAVE offers a promising step towards robust, real-time, non-invasive prosthetic control.",
    "published": "2025-05-23T11:44:33Z",
    "link": "http://arxiv.org/abs/2506.18749v1"
  },
  {
    "title": "A Bio-mimetic Neuromorphic Model for Heat-evoked Nociceptive Withdrawal Reflex in Upper Limb",
    "summary": "The nociceptive withdrawal reflex (NWR) is a mechanism to mediate interactions and protect the body from damage in a potentially dangerous environment. To better convey warning signals to users of prosthetic arms or autonomous robots and protect them by triggering a proper NWR, it is useful to use a biological representation of temperature information for fast and effective processing. In this work, we present a neuromorphic spiking network for heat-evoked NWR by mimicking the structure and encoding scheme of the reflex arc. The network is trained with the bio-plausible reward modulated spike timing-dependent plasticity learning algorithm. We evaluated the proposed model and three other methods in recent studies that trigger NWR in an experiment with radiant heat. We found that only the neuromorphic model exhibits the spatial summation (SS) effect and temporal summation (TS) effect similar to humans and can encode the reflex strength matching the intensity of the stimulus in the relative spike latency online. The improved bio-plausibility of this neuromorphic model could improve sensory feedback in neural prostheses.",
    "published": "2025-05-23T10:41:20Z",
    "link": "http://arxiv.org/abs/2505.17724v1"
  },
  {
    "title": "Recognition of Unseen Combined Motions via Convex Combination-based EMG Pattern Synthesis for Myoelectric Control",
    "summary": "Electromyogram (EMG) signals recorded from the skin surface enable intuitive control of assistive devices such as prosthetic limbs. However, in EMG-based motion recognition, collecting comprehensive training data for all target motions remains challenging, particularly for complex combined motions. This paper proposes a method to efficiently recognize combined motions using synthetic EMG data generated through convex combinations of basic motion patterns. Instead of measuring all possible combined motions, the proposed method utilizes measured basic motion data along with synthetically combined motion data for training. This approach expands the range of recognizable combined motions while minimizing the required training data collection. We evaluated the effectiveness of the proposed method through an upper limb motion classification experiment with eight subjects. The experimental results demonstrated that the proposed method improved the classification accuracy for unseen combined motions by approximately 17%.",
    "published": "2025-05-21T07:46:26Z",
    "link": "http://arxiv.org/abs/2505.15218v1"
  },
  {
    "title": "HDE-Array: Development and Validation of a New Dry Electrode Array Design to Acquire HD-sEMG for Hand Position Estimation",
    "summary": "This paper aims to introduce HDE-Array (High-Density Electrode Array), a novel dry electrode array for acquiring High-Density surface electromyography (HD-sEMG) for hand position estimation through RPC-Net (Recursive Prosthetic Control Network), a neural network defined in a previous study. We aim to demonstrate the hypothesis that the position estimates returned by RPC-Net using HD-sEMG signals acquired with HDE-Array are as accurate as those obtained from signals acquired with gel electrodes. We compared the results, in terms of precision of hand position estimation by RPC-Net, using signals acquired by traditional gel electrodes and by HDE-Array. As additional validation, we performed a variance analysis to confirm that the presence of only two rows of electrodes does not result in an excessive loss of information, and we characterized the electrode-skin impedance to assess the effects of the voltage divider effect and power line interference. Performance tests indicated that RPC-Net, used with HDE-Array, achieved comparable or superior results to those observed when used with the gel electrode setup. The dry electrodes demonstrated effective performance even with a simplified setup, highlighting potential cost and usability benefits. These results suggest improvements in the accessibility and user-friendliness of upper-limb rehabilitation devices and underscore the potential of HDE-Array and RPC-Net to revolutionize control for medical and non-medical applications.",
    "published": "2025-05-20T17:44:21Z",
    "link": "http://arxiv.org/abs/2505.14658v1"
  },
  {
    "title": "Mitigating Compensatory Movements in Prosthesis Users via Adaptive Collaborative Robotics",
    "summary": "Prosthesis users can regain partial limb functionality, however, full natural limb mobility is rarely restored, often resulting in compensatory movements that lead to discomfort, inefficiency, and long-term physical strain. To address this issue, we propose a novel human-robot collaboration framework to mitigate compensatory mechanisms in upper-limb prosthesis users by exploiting their residual motion capabilities while respecting task requirements. Our approach introduces a personalised mobility model that quantifies joint-specific functional limitations and the cost of compensatory movements. This model is integrated into a constrained optimisation framework that computes optimal user postures for task performance, balancing functionality and comfort. The solution guides a collaborative robot to reconfigure the task environment, promoting effective interaction. We validated the framework using a new body-powered prosthetic device for single-finger amputation, which enhances grasping capabilities through synergistic closure with the hand but imposes wrist constraints. Initial experiments with healthy subjects wearing the prosthesis as a supernumerary finger demonstrated that a robotic assistant embedding the user-specific mobility model outperformed human partners in handover tasks, improving both the efficiency of the prosthesis user's grasp and reducing compensatory movements in functioning joints. These results highlight the potential of collaborative robots as effective workplace and caregiving assistants, promoting inclusion and better integration of prosthetic devices into daily tasks.",
    "published": "2025-05-03T07:05:19Z",
    "link": "http://arxiv.org/abs/2505.01718v1"
  },
  {
    "title": "A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities",
    "summary": "This paper introduces a novel AI vision-enabled pediatric prosthetic hand designed to assist children aged 10-12 with upper limb disabilities. The prosthesis features an anthropomorphic appearance, multi-articulating functionality, and a lightweight design that mimics a natural hand, making it both accessible and affordable for low-income families. Using 3D printing technology and integrating advanced machine vision, sensing, and embedded computing, the prosthetic hand offers a low-cost, customizable solution that addresses the limitations of current myoelectric prostheses. A micro camera is interfaced with a low-power FPGA for real-time object detection and assists with precise grasping. The onboard DL-based object detection and grasp classification models achieved accuracies of 96% and 100% respectively. In the force prediction, the mean absolute error was found to be 0.018. The features of the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted micro camera for artificial sensing, enabling a wide range of hand-based tasks; b) real-time object detection and distance estimation for precise grasping; and c) ultra-low-power operation that delivers high performance within constrained power and resource limits.",
    "published": "2025-04-22T07:23:51Z",
    "link": "http://arxiv.org/abs/2504.15654v2"
  },
  {
    "title": "Smart Ankleband for Plug-and-Play Hand-Prosthetic Control",
    "summary": "Building robotic prostheses requires a sensor-based interface designed to provide the robotic hand with the control required to perform hand gestures. Traditional Electromyography (EMG) based prosthetics and emerging alternatives often face limitations such as muscle-activation limitations, high cost, and complex calibrations. In this paper, we present a low-cost robotic system composed of a smart ankleband for intuitive, calibration-free control of a robotic hand, and a robotic prosthetic hand that executes actions corresponding to leg gestures. The ankleband integrates an Inertial Measurement Unit (IMU) sensor with a lightweight neural network to infer user-intended leg gestures from motion data. Our system represents a significant step towards higher adoption rates of robotic prostheses among arm amputees, as it enables one to operate a prosthetic hand using a low-cost, low-power, and calibration-free solution. To evaluate our work, we collected data from 10 subjects and tested our prototype ankleband with a robotic hand on an individual with an upper-limb amputation. Our results demonstrate that this system empowers users to perform daily tasks more efficiently, requiring few compensatory movements.",
    "published": "2025-03-22T19:45:12Z",
    "link": "http://arxiv.org/abs/2503.17846v2"
  },
  {
    "title": "Bring Your Own Grasp Generator: Leveraging Robot Grasp Generation for Prosthetic Grasping",
    "summary": "One of the most important research challenges in upper-limb prosthetics is enhancing the user-prosthesis communication to closely resemble the experience of a natural limb. As prosthetic devices become more complex, users often struggle to control the additional degrees of freedom. In this context, leveraging shared-autonomy principles can significantly improve the usability of these systems. In this paper, we present a novel eye-in-hand prosthetic grasping system that follows these principles. Our system initiates the approach-to-grasp action based on user's command and automatically configures the DoFs of a prosthetic hand. First, it reconstructs the 3D geometry of the target object without the need of a depth camera. Then, it tracks the hand motion during the approach-to-grasp action and finally selects a candidate grasp configuration according to user's intentions. We deploy our system on the Hannes prosthetic hand and test it on able-bodied subjects and amputees to validate its effectiveness. We compare it with a multi-DoF prosthetic control baseline and find that our method enables faster grasps, while simplifying the user experience. Code and demo videos are available online at https://hsp-iit.github.io/byogg/.",
    "published": "2025-03-01T12:35:05Z",
    "link": "http://arxiv.org/abs/2503.00466v1"
  }
]